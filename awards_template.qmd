---
title: "Grant title" # You can change this title
subtitle: "An Analysis of the Past Awards since 2017" # You can replace the subtitle
date: today
author: 
  - name: "[Kadir Jun Ayhan](https://ayhan.phd)" # Change the name and the link.
    degrees: Ph.D. # You can remove this line.
    affiliations: James Madison University # Change the name of the university.
    email: ayhankx@jmu.edu # Change the email address.
    phone: 000-000-0000 # Change the phone number.
format: 
  html:
    theme: jmu.scss # comment this if you don't want to use my custom JMU theme. Or you can edit the colors in that file.
    title-block-banner: "#450084" # you can change the color of the title block banner. Check out hex codes for your preferred colors. 
    title-block-banner-color: "#CBB677" # you can change the color of the text in the title block banner. Check out hex codes for your preferred colors.
    toc: true
editor: visual
warning: false
echo: false
embed-resources: true
---

```{r}
# Uncomment the following lines if you want to install these packages. You only need to this once. You can uncomment by removing hashtags.

# install.packages("tidyverse")
# install.packages("tidytext")
# install.packages("stopwords")
# install.packages("topicmodels")
# install.packages("tm")
# install.packages("ggraph")
# install.packages("igraph")
# install.packages("janitor")
# install.packages("ggeasy")
# install.packages("reshape2")

```

```{r}
# You need to load the libraries each time to use them just like you open an app to use it on your phone.

library(tidyverse) # Data manipulation and visualization
library(janitor) # Data cleaning tools
library(tidytext) # Text mining and processing
library(stopwords) # Access to stopword lists
library(topicmodels) # For topic modeling
library(tm) # Text mining utilities
library(ggraph) # For creating graph-based visualizations
library(igraph) # Graph analysis
library(ggeasy) # Easy labeling of ggplot2 graphs

```

```{r}

# Load the data. Replace the name of the file with the name of your file name.

# sample data from NSF Division of Social and Economic Sciences (SBE/SES) https://www.nsf.gov/awardsearch/advancedSearchResult?ProgOrganization=04050000

awards <- read_csv("data/awards.csv", locale = locale(encoding = "Latin1"))
```

```{r}

# Basic Data Cleaning

# If the column names for the amount or date are different, replace all instances of "awarded_amount_to_date" with the correct column name for amount, and the same for "last_amendment_date." You can do that by using the find and replace feature by clicking CTRL+F or Command+F.
# 
# The date format is set to "%m/%d/%Y" (e.g., 05/15/2024) in the code below. If your date format in the csv file is different, you can change it accordingly. See this [page](https://www.geeksforgeeks.org/how-to-use-date-formats-in-r/).

# Clean the column names and the data to make them more readable and usable.
awards <- janitor::clean_names(awards)

# Making sure the data types are correct.
# If the column name for the amount is different, replace all instances of "awarded_amount_to_date" with the correct column name for amount. You can do that by using the find and replace feature by clicking CTRL+F or Command+F.

# For now, I will focus on projects with titles starting with 'Collaborative Research' to demonstrate data filtering. Remove or uncomment this line if you don't want to filter anything based on title.

# If you indeed want to filter based on title, you can change the title to whatever you want. You can also use regex to filter based on a pattern. For example, if you want to filter for titles that contain "Collaborative Research" OR "Collaborative" OR "Research," you can use str_detect(title, "Collaborative|Research") instead. For more on regex, see this page: https://r4ds.hadley.nz/regexps.html.

awards <- awards |>
  filter(str_detect(title, "Collaborative Research"))

# if the amount is already numeric, comment the following line.

awards$awarded_amount_to_date <- parse_number(awards$awarded_amount_to_date)

# If the column name for the date is different, replace all instances of "last_amendment_date" with the correct column name for date. You can do that by using the find and replace feature by clicking CTRL+F or Command+F.

# The date format is set to "%m/%d/%Y" (e.g., 05/15/2024) in the code below. If your date format in the csv file is different, you can change it accordingly. See this page: https://www.geeksforgeeks.org/how-to-use-date-formats-in-r/.

awards$last_amendment_date <- parse_date(awards$last_amendment_date, format = "%m/%d/%Y")


# Filter for the years you are interested in. Replace 2016 with the year you are interested in. Greater than 2016 will give you the years after 2016, not including 2016.
awards <- awards |>
  filter(year(last_amendment_date) > 2016)

# remove <br/> <br/> in the abstract column

awards$abstract <- gsub("</>|<br/>|\r\r|\r \r|This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.", " ", awards$abstract)


```

# Introduction

You can write your introduction here. This section is not code. You can write your introduction in plain text.

# Awarded Amounts Option 1

```{r}

# Some awards are collaborative, meaning the same project (with the same title and abstract) may have multiple entries because the funding is divided across institutions. This code aggregates the amount for collaborative projects.

awards_g <- awards |>
  group_by(title) |>
  summarize(n = n(),
            amount = sum(awarded_amount_to_date, na.rm = T)) |>
  ungroup()

```

If the awarded amount range is "normal," you can use the following code. Otherwise, delete the following code chunk.

```{r}

# This code creates a density plot of the awarded amounts. You can change the color of the lines by changing the hex color codes. You can also change the x and y axis labels by changing the text in the labs function.

density <- awards_g |>
  ggplot(aes(round(amount/1e3))) + #dividing by 1000
  geom_density() +
  geom_vline(xintercept = median(round(awards_g$amount/1e3)), color = "#450084") +
  geom_vline(xintercept = mean(round(awards_g$amount/1e3)), color = "#450084") +
  geom_text(aes(x = median(round(amount/1e3)), y = Inf, label = "Median"), color = "#450084", vjust=1,hjust=2.1,size=5,angle=90) +
  geom_text(aes(x = mean(round(amount/1e3)), y = Inf, label = "Mean"), color = "#450084", vjust=1,hjust=2.1,size=5,angle=90) +
  scale_x_continuous(breaks = c(seq(0, max(round(awards_g$amount/1e3)), by = 1000))) +
  #coord_flip() +
  labs(x = "Awarded Amounts (in $1000)",
       y = "Density") +
  theme_void() +
  theme(legend.position="none",
        element_text(color = '#A4232B'),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1),
        axis.title.x = element_text(colour = "#A4232B"),
  panel.background = element_rect(fill = "#F4EFE1"))

density

# Save the plot to a file. You can change the file name and the path to the file.

ggsave("figures/density_normal.png", density, dpi = 300)
```

# Awarded Amounts Option 2

If the awarded amounts are skewed, as in this example, you can use the following code which takes the log of the awarded amounts. Make sure to delete Option 1 then.

```{r}

density_log <- awards_g |>
  ggplot(aes(round(amount/1e3))) +
  geom_density() +
  scale_x_continuous(trans='log2', 
                     breaks = c(2^seq(0, ceiling(log2(max(round(awards_g$amount/1e3))))), round(mean(round(awards_g$amount/1e3)),0), round(median(round(awards_g$amount/1e3)),0))) +
  geom_vline(xintercept = median(round(awards_g$amount/1e3)), color = "#450084") +
  geom_vline(xintercept = mean(round(awards_g$amount/1e3)), color = "#450084") +
  geom_text(aes(x = median(round(amount/1e3)), y = Inf, label = "Median"), color = "#450084", vjust=1,hjust=2.1,size=5,angle=90) +
  geom_text(aes(x = mean(round(amount/1e3)), y = Inf, label = "Mean"), color = "#450084", vjust=1,hjust=2.1,size=5,angle=90) +
  labs(x = "Awarded Amounts in $1000 (log transformed)",
       y = "Density") +
  theme_void() +
  theme(legend.position="none",
        element_text(color = '#A4232B'),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1),
        axis.title.x = element_text(colour = "#A4232B"),
  panel.background = element_rect(fill = "#F4EFE1"))


density_log

# Save the plot to a file. You can change the file name and the path to the file.

ggsave("figures/density_log.png", density_log, dpi = 300)

```

This is text and inline code. The average of filtered [NSF Division of Social and Economic Sciences (SBE/SES)](https://www.nsf.gov/awardsearch/simpleSearchResult?queryText=diplomacy&ActiveAwards=true) projects is `r paste0("$", format(mean(awards_g$amount), big.mark = ",", scientific = FALSE))`. The median amount is `r paste0("$", format(median(awards_g$amount), big.mark = ",", scientific = FALSE))`.

# Abstract Analysis

## Word Frequency in Abstracts

```{r}

# Remove duplicate titles
awards_abstracts <- awards |> distinct(title, .keep_all = TRUE)



custom_stopwords <- c("will", "can", "br", "s", "g", "e", "(anr).", "project", "research", "study", "results", "across")

awards_abstracts$abstract <- awards_abstracts$abstract |> 
  str_squish() |>  # Remove extra whitespace
  tolower()         # Convert to lowercase
  

text_corpus <- Corpus(VectorSource(awards_abstracts$abstract)) |> 
  # tm_map(content_transformer(function(x) gsub("</>|<br/>", " ", x))) |> # Remove HTML tags
  tm_map(removePunctuation) |> # Remove punctuation
  tm_map(removeNumbers) |> # Remove numbers
    tm_map(removeWords, custom_stopwords) |> # Remove custom stopwords
  tm_map(removeWords, stopwords("english")) |> # Remove default stopwords
  tm_map(stripWhitespace) # Remove extra whitespace

tdm <- TermDocumentMatrix(text_corpus) # Create a term-document matrix
word_freqs <- sort(rowSums(as.matrix(tdm)), decreasing = TRUE) # Sort terms by frequency
tdm_df <- data.frame(word = names(word_freqs), freq = word_freqs) # Create a data frame for the word frequencies

set.seed(1234)

freq <- ggplot(tdm_df[1:20,], aes(x = reorder(word, freq), y = freq)) + # Plot top 20 most frequent words
  geom_bar(stat = "identity", fill = "#450084") +
  coord_flip() + # Flip axes for better readability
  labs(x = "Terms", y = "Count", title = "Most Common Words in Abstracts") +
  ggeasy::easy_center_title() + # Center the title in the plot
  theme_void() + # Remove background elements
  theme(axis.text.y = element_text(size = 12),
        axis.text.x = element_text(size = 12),
        axis.title = element_text(size = 12),
        element_text(color = '#A4232B'),
        axis.title.x = element_text(colour = "#A4232B"),
        axis.title.y = element_text(colour = "#A4232B"),
        panel.background = element_rect(fill = "#F4EFE1")) 

freq

ggsave("figures/freq.png", freq, dpi = 300)
```

## Topic Modeling in Abstracts

```{r}
# Here, all you need to do is decide how many topics you want to extract. I will use 4 topics in this example. You can change the number of topics by changing the value of "k" in the LDA function. Play around with it to see what works best for your data.

dtm <- DocumentTermMatrix(text_corpus)

# Remove empty documents from the dtm
row_totals <- rowSums(as.matrix(dtm))  # Compute row-wise term sums
dtm <- dtm[row_totals > 0, ]  # Keep only non-empty rows


lda <- LDA(dtm, k = 4, control = list(seed = 1234))
 
topics <- tidy(lda, matrix = "beta")

 
top_terms <- topics |>
  group_by(topic) |>
  slice_max(beta, n = 10) |>
  ungroup() |>
  arrange(topic, -beta)

# Define your custom color palette
jmu_palette <- c("#450084", "#CBB677", "#5498B6", "#A4232B", "#5F791C")

# Apply the custom color palette to your plot
tm <- top_terms |>
  mutate(term = reorder_within(term, beta, topic)) |>
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered() +
  scale_x_continuous(labels = scales::percent_format(accuracy = 0.1)) +
  theme_void() +
  scale_fill_manual(values = jmu_palette) +  # Add this line
  theme(axis.text.y = element_text(size = 12),
        axis.text.x = element_text(size = 12),
        axis.title = element_text(size = 12),
        element_text(color = '#A4232B'),
        axis.title.x = element_text(colour = "#A4232B"),
        axis.title.y = element_text(colour = "#A4232B"),
        panel.background = element_rect(fill = "#F4EFE1"))

tm

ggsave("figures/tm.png", tm, dpi = 300)
```

## Word Networks (Bigrams) in Abstracts

```{r}

awards_abstracts <- awards_abstracts |>
  select(title, abstract) # Select only the title and abstract columns
  
bigrams <- awards_abstracts |> 
  unnest_tokens(bigram, abstract, token = "ngrams", n = 2) |> # Tokenize into bigrams
  separate(bigram, c("word1", "word2"), sep = " ") |> # Split bigrams into two words
  filter(!word1 %in% c(stopwords("english"), custom_stopwords),
         !word2 %in% c(stopwords("english"), custom_stopwords)) # Remove stopwords from bigrams

bigram_counts <- bigrams |> count(word1, word2, sort = TRUE) # Count bigram frequencies

# We will create a graph from the bigrams. You can change the threshold for filtering the bigrams by changing the value of "n" in the filter function. I will use 20 in this example to include only the bigrams that appear more than 20 or more times. You can change it to whatever you want.

bigram_graph <- bigram_counts |> filter(n >= 20) |> # Filter to include only bigrams with frequency > 40
  igraph::graph_from_data_frame() # Create a graph from the bigram data frame

set.seed(123)


bigram <- ggraph(bigram_graph, layout = "fr") + # Create a force-directed graph of bigrams
  geom_edge_link(color = "#450084") +
  geom_node_point(color = "#450084") +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1, repel = TRUE, color = "#450084") + # Add labels to nodes with repelling effect
  theme_void() + # Remove background elements
  theme(panel.background = element_rect(fill = "#F4EFE1"),
        element_text(color = '#A4232B'))

bigram

ggsave("figures/bigram.png", bigram, dpi = 300)
```

## Bigram Frequency in Descriptions

```{r}

bigram_freq <- ggplot(bigram_counts[1:20,], aes(x = reorder(paste0(word1, " ", word2), n), y = n)) + # Plot top 20 most frequent words
  geom_bar(stat = "identity", fill = "#450084") +
  coord_flip() + # Flip axes for better readability
  labs(x = "Bigrams", y = "Count", title = "Most Common Bigrams in Abstracts") +
  theme_void() + # Remove background elements
  # make the font size bigger
  theme(axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 10),
        axis.title = element_text(size = 10),
        element_text(color = '#A4232B'),
        axis.title.x = element_text(colour = "#A4232B"),
        axis.title.y = element_text(colour = "#A4232B")
        ) +
  #theme_void() + # Remove background elements
  theme(panel.background = element_rect(fill = "#F4EFE1")) +
  ggeasy::easy_center_title() # Center the title in the plot

bigram_freq

ggsave(here::here("figures/bigram_freq.png"), plot = bigram_freq, dpi = 300)
```

# Abstract Takeaways

Write your analysis here.

# AI Summary of Awarded Proposals

```{r}
# exporting the abstract data to a csv file.

write_csv(awards_abstracts, "data/awards_abstracts.csv")
```

Open the created csv file (awards_abstract file in the data folder) in Excel or another program, and save it as a .pdf file.

Then go to NotebookLM, and upload the pdf file. You can then use the AI to summarize and categorize the abstracts.

You can also use other AI tools for this task.
